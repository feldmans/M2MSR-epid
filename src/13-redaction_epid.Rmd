---
title: 'DEVOIR EPIDEMIOLOGIE : UTILISATION DU SCORE DE PROPENSION'
author: "Sarah F FELDMAN"
date: "27 février 2017"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(knitr)
source("01-library_EPID.R")
source("02-functions_EPID.R")
knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(echo=FALSE, comment=NA, fig.width=6, fig.height=6)
#opts_chunk$set(fig.width=6, fig.height=6)
```

# INTRODUCTION

Le cathétérisme cardiaque droit (CCD) est un examen invasif utilisé en soins intensif pour mesurer directement la fonction cardiaque, ce qui permettrait selon certains médecins une meilleure prise en charge du patient et donc une augmentation de la survie. Cependant pour montrer une telle causalité il faudrait un essai randomisé. Or nous avons ici les données d'une cohorte prospective, non interventionnelle, de patients hostpitalisés en réanimation, certains ayant été cathétérisés, d'autres non. La cathétérisation n'a pas été randomisée, il y a donc lieu de penser que l'examen a été réalisé préférentiellement chez certains types de patients, potentiellement les patients les plus graves qui ont donc plus de risque de décéder. Cela constitue un biais d'indication qui rend l'analyse de l'efficacité du CCD  ininterprêtable. Pour pouvoir analyser l'efficacité du CCD par sonde de swan Ganz, nous allons prendre en compte les biais d'indication propables à l'aide d'un score de propension, nous permettant d'améliorer le niveau de causalité de la relation CCD/Décès si elle existe.

# DESCRIPTION DE LA BASE DE DONNEES

```{r}
.dir <- dirname(getwd())

d <- read.csv2(paste0(.dir,"/data/rhc_devoir_epidemio.csv"))

dim(d)
length(unique(d$PTID))
```
Base de données de 5735 lignes et 63 colonnes. Ce sont des données transversales avec une ligne par patient (pas de doublon), chaque variable ayant été mesurées une seule fois.

# doublons


## Data management
```{r}
#data management

d$SADMDTE <- as.Date(d$SADMDTE,"%d/%m/%Y") 
d$DSCHDTE <- as.Date(d$DSCHDTE,"%d/%m/%Y") 
d$DTHDTE <- as.Date(d$DTHDTE,"%d/%m/%Y") 
d$LSTCTDTE <- as.Date(d$LSTCTDTE,"%d/%m/%Y")

for (i in c("DEATH", "DTH30", "DNR1", "RESP", "CARD", "NEURO", "GASTR", "RENAL", "META", "HEMA", "SEPS", "TRAUMA", "ORTHO")) {
  d[ ,i] <- as.character(d[,i])
  d[,i] <- ifelse (d[ ,i]=="No", 0, d[ ,i])
  d[,i] <- ifelse (d[ ,i]=="Yes", 1, d[ ,i])
  d[,i] <- as.numeric(d[,i])
}
#Pour transformer les "" en NA
#plus long que apply mais garde la bonne structure

#Je repère les variables avec ""
for (x in colnames(d)){
  if(is.factor(d[ ,x])) {
    if(length(d[d[ ,x]=="", x])!=0) {
      print(x)
    } 
  }
}
#CAT2

#Pour CAT2 je crée à la place une cathégorie "NoCAT", pour DSCHDTE et DTHDTE je transforme "" en NA
d$CAT2 <- as.character(d$CAT2)
d$CAT2 <- ifelse (d$CAT2=="", "NoCAT2", d$CAT2)
d$CAT2 <- as.factor(d$CAT2)

#Je préfère que PTID soit un caractère pour éviter un gag si le numéro de ligne n'est pas le même que PTID
d$PTID <- paste0("A", d$PTID)

#variables cathétérisme: 
#Variable SWAN Ganz en en 0/1 pour matchit
d$SWAN <- d$SWANG1
levels(d$SWAN) <- c(0, 1)
#J'en fais une autre en T/F pour le package Matching
d$SWANT <- ifelse(d$SWAN==1, T, F)

#Outcomes
d$DEATH <- as.factor(d$DEATH)
# d$DEATH2 <- ifelse(!is.na(d$DTHDTE), 1, 0)
# table(d$DEATH==d$DEATH2) #5735 true 0 false => la variable DEATH est correcte

#var pour analyse de survie
table(is.na(d$LSTCTDTE)) #pas de perdu de vu pour la date de dernier contact
#3 patients pour lesquels la date de décès est antérieure à la date de derniere nouvelle
#2151 pour lesquels date de dernières nouvelles est antérieure au décès.
table(d$DTHDTE < d$LSTCTDTE)
# d[d$DTHDTE < d$LSTCTDTE & !is.na(d$DTHDTE), c("DTHDTE", "LSTCTDTE")]
# d[d$DTHDTE > d$LSTCTDTE & !is.na(d$DTHDTE), c("DTHDTE", "LSTCTDTE")]

#=> Je modifie LSTCTDTE : si décès, alors la date de dernière nouvelle est la date de décès.
d$LSTCTDTE <- as_date(ifelse(is.na(d$DTHDTE), d$LSTCTDTE, d$DTHDTE))
#d$ddn <- as_date(ifelse(is.na(d$DTHDTE), d$LSTCTDTE, d$DTHDTE))

#temps de suivi en j entre la date des dernières nouvelles (décès ou date de dernier contact)
d$time <- as.numeric(d$LSTCTDTE - d$SADMDTE) 
#avant d'utiliser la variable DTH30 dans une régression logistique, je vérifie que tous les sujets sont bien suivis au moins 30j. Si non, alors ils sont NA pour le décès et non pas 0 car on ne tient pas compte du temps.
table(d$time<=30, d$DEATH) #j'ai 8 sujets qui sont perdus de vu avant 30 jours et non décédés
namesDTH30_NA <- d[d$time<=30 & d$DEATH==0, "PTID"]
d$DTH30b <- NA
d$DTH30b <- ifelse (d$time<=30 & d$DEATH==1, 1, d$DTH30b) 
d$DTH30b <- ifelse (d$time>30, 0, d$DTH30b) 
table(d$DTH30b)
table(d$DTH30)
#Je ne suis pas d'accord avec la variable DTH30 qui note 0 les sujets perdus de vu  avant 30 j. Ce serait ok pour un modele de survie prenant en compte de le temps de suivi mais
#pas pour une régression logistique.

#pour faire analyse de survie avec DTH30:
d$timeb <- ifelse(d$time>30, 30, d$time)


#Après avoir lu Connors 1996 :
#Je renomme les niveaux de CA,
levels(d$CA) <- c("Metastatic", "No", "Localized")
d$CA <- relevel(d$CA, ref = "No")
#La variable length of stay prior to study entry n'est a priori pas réalisable avec les données dont je dispose mais c'est par contre la durée dans l'étude
quantile(as.numeric(d$DSCHDTE - d$SADMDTE)[d$SWAN==0])
quantile(as.numeric(d$DSCHDTE - d$SADMDTE)[d$SWAN==1], na.rm=T)

```


3 patients pour lesquels la date de décès est antérieure à la date de derniere nouvelle -->
2151 pour lesquels date de dernières nouvelles est antérieure au décès. -->

Avant d'utiliser la variable DTH30 dans une régression logistique, je vérifie que tous les sujets non décédés sont bien suivis au moins 30j. Si non, alors ils sont NA pour le décès et non pas 0 car on ne tient pas compte du temps.  8 sujets sont perdus de vu avant 30 jours et non décédés, ils sont donc NA pour le décès et non pas 0 comme noté dans la variable DTH30 (ils sont cependant censor = 0 pour une analyse de survie) 

## Je réalise une analyse descriptive préliminaire afin de repérer les incohérences

###Présentation des variables de l'examen clinique et biologique:
Activities of daily living (ADL) : échelle d'autonomie de 0 à 12 (score>6 signe une dépendance)  
Duke Activity Status Index (DASI) : auto-questionnaire de 12 items mesurant l'activité fonctionnelle. Le score va de 0 à 58.2, plus le score est élevé, meilleur est l'activité fonctionnelle. 
DNR pour Do not resuscitate : 1 pour une interdiction de réanimation cardiopulmonaire, 0 sinon.  
Probabilité de survie à 2 mois, estimée par model : de 0 à 1  
APACHE III Acute Physiology scores : score de prediction du risque de mortalité de patients hospitalisés en soins intensifs. Plus le score est élevé plus le risque de mortalité est important. LE score va de 0 à 299 mais ici seule la partie physiologie du score est utilisée.  
Le score de Glasgow évalue l'état de conscience du patient: un score de 3 équivaut à un coma profond, un score de 15 est un état de conscience normal.  
Le rapport PAO2/FIO2 permet de diagnostiquer une agression pulmonaire aigue(rapport>300), un rapport <200 definissant le syndrome de detresse respiratoire aigue et l'ECMO est envisageable en cas de rapport <50.
Un pH normal varie entre 7,38 et 7.42, le taux d'hématocrite normal est comprise entre 41 et 50% environ, La PaCO2 normale varie de 35 à 45mmHg.  
Le taux d'albumine normal varie entre 25 et 44 g/L.  


```{r}
#1/ Je regroupe mes variables pour faciliter la présentation de l'analyse
#variables socio demo
vardes <- c("AGE", "SEX", "RACE", "EDU", "INCOME", "NINSCLAS")
var_quali_des <- c("SEX", "RACE", "INCOME", "NINSCLAS")
var_quanti_des <- c("AGE","EDU")
#variables antécédents médicaux
var_atcd <-  c("CAT1", "CAT2", "CA")
#date
var_date <- c("SADMDTE", "DSCHDTE", "DTHDTE", "LSTCTDTE")
# variables de comorbidités
var_com <- c("CARDIOHX", "CHFHX", "DEMENTHX", "PSYCHHX", "CHRPULHX", "RENALHX",
             "LIVERHX", "GIBLEDHX", "MALIGHX", "IMMUNHX", "TRANSHX", "AMIHX")
#variables de l'examen clinique et paraclinique
var_exam <- c("ADLD3P", "DAS2D3PC", "DNR1", "SURV2MD1", "APS1", "SCOMA1", "WTKILO1", "TEMP1",
              "MEANBP1", "RESP1", "HRT1", "PAFI1", "PACO21", "PH1", "WBLC1", "HEMA1", "SOD1", "POT1",
              "CREA1", "BILI1", "ALB1", "URIN1")
#var admission diagnosis
var_ad <- c("RESP", "CARD", "NEURO", "GASTR", "RENAL", "META", "HEMA", "SEPS", "TRAUMA", "ORTHO")

#JE vérifie qu'elles sont toutes là
colnames(d)[!colnames(d) %in% c(var_quali_des, var_quanti_des, var_atcd, var_date, var_com, var_exam, var_ad)]

#2/ Je fais un tableau descriptif pour répérer d'éventuels incohérence

do.call(rbind, lapply(c(var_quali_des, var_quanti_des, var_atcd, var_com, var_exam, var_ad), describe_all, d))
write.table(print(do.call(rbind, lapply(c(var_quali_des, var_quanti_des, var_atcd, var_com, var_exam, var_ad), describe_all, d))), file="clipboard", sep="\t")
range(d$LSTCTDTE)
range(d$SADMDTE)


#3/ Nb de NA
#Nb de sujets avec 0, 1, 2, 3, 4 NA 
table(apply(apply(d,2,is.na),1,sum))
#cb de NA pour chaque colonne
apply(apply(d,2,is.na),2,sum)
table(apply(apply(d,2,is.na),2,sum))

prop.table(table(is.na(d$ADLD3P)))
prop.table(table(is.na(d$URIN1)))

#4/ Nb de duplicatas
d[duplicated(d$PTID),]

```
ADLD3P et URIN1 ont respectivivement 75% et 53% de données manquantes tandis que les autres variables n'ont aucune ou moins de 5% de données manquantes. Je ne prendrai donc pas en compte ces deux variables dans le calcul du score de propension et je laisse les autres variables telles quelles pour le moment. 
Il n'y a pas de doublon.

```{r, eval=FALSE}
#4/ distribution des items
.l <- lapply(colnames(d), function(x){
  if (class(d[,x])=="Date") {
    #browser()
    qplot(d[ ,x], main=x, xlab=NULL, fill=I("navajowhite3"), col=I("pink4"))
  }
  else{
    if (length(names(table(d[,x])))>15) qplot(as.numeric(as.character(d[ ,x])), main=x, xlab=NULL, fill=I("navajowhite3"), col=I("pink4"))
    else qplot(as.factor(d[ ,x]), main=x, xlab=NULL, fill=I("navajowhite3"), col=I("pink4"))  
  }
  
})
ml <- marrangeGrob(.l,ncol=3,nrow=3,top = NULL)
ggsave(file="distrib bef dm.pdf", ml)
print(ml)



```


## Je croise les variables pour chercher d'autres incohérences

```{r}
#creation d'une variables permettant d'observer le profil des patients ayant FC, et/ou FR et/ou TA =0
HR0 <- ifelse(d$HRT1==0, "FC0", ifelse(!is.na(d$HRT1),0,NA))
FC0 <- ifelse(d$RESP1==0, "FR0", ifelse(!is.na(d$RESP1),0,NA))
TA0 <- ifelse(d$MEANBP1==0, "TA0", ifelse(!is.na(d$MEANBP1),0,NA))
#pas de NA de toutes façons pour ces valeurs
d$cleCR <- paste(HR0, FC0, TA0, sep="|")
table(d$cleCR)
d[d$cleCR=="FC0|FR0|0", c("HRT1", "RESP1", "MEANBP1", "DTH30", "SCOMA1", "TEMP1")]

```
J'ai observé ensemble la fréquence cardiaque, la fréquence respiratoire et la tension artérielle. J'observe certaines incohérences : parfois 2 de ces variables peuvent valoir 0 mais pas la troisième, et parfois une seule de ces variables vaut 0.



```{r}
#"0|0|0" :aucune valeure ne vaut 0, ok
#"0|0|TA0" : LA tension artérielle vaut 0 mais pas le reste : probable erreur de mesure
d$MEANBP1 <- ifelse(d$cleCR=="0|0|TA0", NA, d$MEANBP1)
#"0|FR0|0"  : réa probablement pas d'accord sur quoi mesurer faire en cas de respirateur : chercher variable respirateur, sinon garder telle quelle? 
#"0|FR0|TA0" : TA 0 et respi 0, je mets la FC à 0 aussi
d$HRT1 <- ifelse(d$cleCR=="0|FR0|TA0", 0, d$HRT1)
#"FC0|0|0" : seul la FC vaut0 : erreur, FC =NA
d$HRT1 <- ifelse(d$cleCR=="FC0|0|0", NA, d$HRT1)
#"FC0|0|TA0" : probablement encore une histoire de respirateur : si TA et FC vaut 0, alors FR aussi   
d$RESP1 <- ifelse(d$cleCR=="FC0|0|TA0", 0, d$RESP1)
#"FC0|FR0|0" : quelq'un qui ne respire pas et n'a pas de pouls a une tenion nulle également
d$MEANBP1 <- ifelse(d$cleCR=="FC0|FR0|0", 0, d$MEANBP1)
#"FC0|FR0|TA0" : toutes les valeurs sont à 0 ok 

#Je supprime la clé
d$cleCR <- NULL

#recodage du poids:
d$WTKILO1 <- ifelse(d$WTKILO1==0, NA, d$WTKILO1) #kilo max 244 ok (j'en ai vu) #515 poids = 0! 
#recodage de l'hématocrite
d$HEMA1 <- ifelse(d$HEMA1<10, NA, d$HEMA1)
#recodage de la PACO2
d$PACO21 <- ifelse(d$PACO21>100, NA, d$PACO21)
#recodage de l'albumine
d$ALB1 <- ifelse(d$ALB1>10, NA, d$ALB1)

#Je regarde à nouveau le nombre de données manquantes
#Nb de sujets avec 0, 1, 2, 3, 4 NA 
table(apply(apply(d,2,is.na),1,sum))
#cb de NA pour chaque colonne
apply(apply(d,2,is.na),2,sum)
table(apply(apply(d,2,is.na),2,sum))
```
Les scores qui ont été mesurés, semblent tous avoir des résultats plausibles excepté le score de Glasgow qui a été modifié : d'un score allant de 3 à 15 on passe à un score allant de 0 à 100. Le score de 100 est probablement lié à un coma sévère car les patients avec un score plus élevé ont un risque de décès augmenté (alors que dans l'échelle d'origine, 3 correspond au coma sévère, et 15 à une conscience normale).  
Je laisse la variable telle quelle car elle a de toute évidence été modifiée, je ne veux pas la remodifier une seconde fois.  
La température corporelle peut aller de 27° en cas d'hypothermie profonde à 42-43° en cas de forte fièvre, donc je ne modifie pas.  
Un patient ne peut pas avoir un poids de 0, ces 515 patients sont recodés en NA pour le poids.  
Un patient peut être en aplasie mais je ne suis pas sûr qu'une hyperleucocytose de plus de 40 leucocytes/10^9L soit possible, cependant dans le doute concernant le taux maximum en cas de leucémie et au vue de la distribution de la variable qui semble plausible, je laisse telle quelle.  
Hematocrite : une anémie chronique peut entrainer une anémie profonde avec une hématocrite de 10%, en dessous de cette valeur je mets NA. (un taux de 66% est possible). 
Un taux de PAcO2 de 156 mmHg me semble complètement impossible, au delà de 100 mmHg je met NA.
Un pH de 6.6 est extrêmement faible et n'est pas viable mais je ne suis pas sûre qu'on ne puisse pas l'observer en réanimation.  
Une créatininémie de 2200umol/L ou 25 mg/dL est possible en cas d'insuffisance rénale terminale. Un volume urinaire de 0 et de 9000mL est possible également.  
Une valeur normale d'albumine se situe entre 3.5 et 5 g/dL. Les patients avec un taux d'albumine supérieur à 10g/dL auront une valeur NA pour l'albumine.

Les valeurs de natrémie, de kaliémie, de fréquence respiratoire, fréquence cardiaque, tension artéirelle et bilirubine semblent plausible


http://www.srlf.org/wp-content/uploads/2015/11/0505-Reanimation-Vol14-N3-p177_185.pdf




Règles de recodage de la fréquence caridaque, de la fréquence respiratoire et de la tension artérielle:
-  Si deux de ces variables valait 0, alors la valeur de 0 était systématiquement attribuée à la troisième.  
-  Si une seule de ces variables valait 0 alors elle était systématiquement transformée en valeur manquante.
Recodage du poids : si le poids est inférieur à 25 je remplace par une valeure manquante.

#Je regarde à quoi correspond la variable SCOMA1

```{r, eval=FALSE}
#refaire en coupant SCOMA1 en classe et recuperer la courbe de survie pour var qualitative
d$SCOMAsup90 <- ifelse(d$SCOMA1>90,1,0)
d$SCOMAcut <- cut(d$SCOMA1, breaks=5)
draw_surv_bin(var="SCOMAsup90", data=d, .time="time", .censor="DEATH", vec_time_IC= c(1, 3), type = "quali", surv_only=FALSE, pvalue = TRUE, dep_temps=FALSE, .transf=NULL)
draw_surv_bin(var="SCOMAsup90", data=d, .time="timeb", .censor="DTH30", vec_time_IC= c(7, 14), type = "quali", surv_only=FALSE, pvalue = TRUE, dep_temps=FALSE, .transf=NULL, .scale="day")
plot(d$SCOMA1, d$APS1) #le score APS ne nous aide pas
#plus score est élevé, plus le risque de deces est eleve. 
ggsurv(survfit(Surv(time, censor)~SCOMAcut, data=d), order.legend =FALSE)

#Je supprime ces 2 variables du tableau
d[ , c("SCOMAsup90", "SCOMAcut")] <- NULL
```



# Description des variables

Je décris les variables dans le groupe des patients cathétérisés, dans le groupe des patients non cathétérisés et les deux groupes confondus.

Variables quantitatives:
-  continues :
-  discrètes :
- binaires
variables qualitatives

```{r}
quanti <- c("AGE","EDU", "ADLD3P", "DAS2D3PC","SURV2MD1", "APS1", "SCOMA1", "WTKILO1", "TEMP1", "MEANBP1", "RESP1", "HRT1", "PAFI1", "PACO21", "PH1", "WBLC1", "HEMA1", "SOD1", "POT1", "CREA1", "BILI1", "ALB1", "URIN1")
binaire <-  binaire <- c("SEX", "CARDIOHX", "CHFHX", "DEMENTHX", "PSYCHHX", "CHRPULHX", "RENALHX", "LIVERHX", "GIBLEDHX", "MALIGHX", "IMMUNHX", "TRANSHX", "AMIHX", "RESP", "CARD", "NEURO", "GASTR", "RENAL", "META", "HEMA", "SEPS", "TRAUMA", "ORTHO")
quali <- c("RACE", "INCOME", "NINSCLAS", "CAT1", "CAT2", "CA")
```
Pause dans les inclusions


# Description avant imputation
```{r}
des_noSWAN <- do.call(rbind, lapply(c(var_quali_des, var_quanti_des, var_atcd, var_com, var_exam, var_ad), describe_all, d[d$SWAN==0, ]))
des_SWAN <- do.call(rbind, lapply(c(var_quali_des, var_quanti_des, var_atcd, var_com, var_exam, var_ad), describe_all, d[d$SWAN==1, ]))
des_all <- do.call(rbind, lapply(c(var_quali_des, var_quanti_des, var_atcd, var_com, var_exam, var_ad), describe_all, d))
des_tot <- cbind(des_noSWAN[ , 1], des_SWAN[ , 1], des_all[ , 1:2])
des_tot <- des_tot[str_sub(rownames(des_tot), -1, -1)!=0, ]
```


# Imputation des valeurs manquantes

Je décide de ne garder que les variables avec moins de 20%de données manquantes et les sujets avec moins de 50% de données manquantes (excepté la variable date de décès bien sûr). Je ne tiens compte que des variables explicatives (je ne tiens pas compte du décès ni du traitement, qui n'est jamais NA de toutes façons, ni des dates d'entrée dans l'étude ou de sortie de l'hopital). J'imputerai les données manquantes restantes. 

Je vais donc dans un premier temps observer les données manquantes par variable et par sujet. 
```{r}
d2 <- d[ , ! colnames(d) %in% c(var_date, "DEATH", "DTH30b")]
nacol <- apply(d2, 2,function(x)sum(is.na(x))/length(x)*100)
nacol[nacol>20]
napat1 <- apply(d2, 1, function(x)sum(is.na(x)))
napat <- apply(d,1,function(x)sum(is.na(x))/length(x)*100)
table(napat1)
table(napat)

#la fonction md.pattern()de la librairie mice fait la même chose mais la sortie est illisible ici car nous avons trop de sujets et trop de variables.
```
Le score d'autonomie ADL a environ 75% de données manquantes et la variable volume d'excrétion urinaire a plus de 50% de données manquantes. Je supprime donc ces deux variables de l'analyse.
250 patient patients n'ont aucune donnée manquante, 5485(95.6%) patients ont au moins 1 donnée manquante dont : 1930 patients avec 1 donnée manquante, 2694 patients avec 2 de données manquantes, 796 patients avec 3 données manquantes, 64 patients avec 4 données manquantes et 1 patient avec 5 données manquantes. Tous les patients ont donc moins de 50% de données manquantes. Je les garde tous dans l'analyse.

Je note également qu'il n'y a pas de valeurs manquantes concernant la variable d'intérêt Swan ganz. Si je prends comme outcome le décès à 30 jours, analysé par régression logistique, j'ai 8 valeurs manquantes (car les sujets ont été censurés avant 30j, et la censure n'est pas prise en charge par le modèle logistique).


```{r}
#je supprime les variables avec plus de 20% de donnees manquantes.
d <- subset(d, select=-c(ADLD3P, URIN1))
d2 <- d[ , ! colnames(d) %in% c(var_date, "DEATH", "DTH30b")]
nacol <- apply(d2, 2,function(x)sum(is.na(x))/length(x)*100)
nacol[nacol>0]
napat1 <- apply(d2, 1, function(x)sum(is.na(x)))
napat <- apply(d2,1,function(x)sum(is.na(x))/length(x)*100)
table(napat1)
table(napat)
```

En supprimant ces 2 colonnes de l'analyse, j'ai 2397 patients avec au moins une donnée manquante, soit plus de 5 % de patients. Je ne peux donc pas simplement supprimer les patients avec des données manquantes.
6 variables ont au moins une donnée manquante : la tension artérielle (15 NA), la fréquence cardiaque (60 NA), l'albuminémie (2 NA) l'hématocrite (8 NA), la PaCO2 (21 NA) et le poids (515 NA). 



```{r, eval=FALSE}
#J'impute ces données manquante par la médiane pour chaque variable.
dput(names(nacol[nacol>0])) #c("MEANBP1", "HRT1", "ALB1", "HEMA1", "PACO21", "WTKILO1")
for (i in c("MEANBP1", "HRT1", "ALB1", "HEMA1", "PACO21", "WTKILO1")){ 
  d[ , i] <- ifelse(is.na(d[ , i]), median(d[ , i], na.rm = T), d[ , i])
}
```

Dans un second temps, je réaliserai une imputation multiple en faisant l'hypothèse que les données manquantes le sont aléatoirement.

```{r}
#mice bug si je laisse les dates
init = mice(d[ ,!colnames(d)%in%var_date], maxit=0) 
meth = init$method
predM = init$predictorMatrix

#Je ne veux pas que les variables ROWNAMES, PTID, SWAN, SWANT, time, DTH30b et timeb soit des prédicteurs.
predM[ ,c("ROWNAMES", "PTID", "SWAN", "SWANT", "time", "DTH30b", "timeb")]=0

#Je ne veux pas que soit prédites les dates de décès DSCHDTE et la variable décès à 30j pour la régression logistique.
meth[c("DTH30b")]=""

#J'impute par imputation multiple
set.seed(103)
imputed = mice(d[ ,!colnames(d)%in%var_date], method=meth, predictorMatrix=predM, m=1)
imputed <- complete(imputed)
d[ ,!colnames(d)%in%var_date] <- imputed
```

# Description après imputation
```{r}
#Je retire ADLD3P et URIN1
var_exam <- c("DAS2D3PC", "DNR1", "SURV2MD1", "APS1", "SCOMA1", "WTKILO1", "TEMP1", "MEANBP1", "RESP1", "HRT1", "PAFI1", "PACO21", "PH1", "WBLC1", "HEMA1", "SOD1", "POT1", "CREA1", "BILI1", "ALB1")
#var_exam <- var_exam [! var_exam %in% c("ADLD3P", "URIN1")]
des_noSWAN <- do.call(rbind, lapply(c(var_quali_des, var_quanti_des, var_atcd, var_com, var_exam, var_ad), describe_all, d[d$SWAN==0, ]))
des_SWAN <- do.call(rbind, lapply(c(var_quali_des, var_quanti_des, var_atcd, var_com, var_exam, var_ad), describe_all, d[d$SWAN==1, ]))
des_all <- do.call(rbind, lapply(c(var_quali_des, var_quanti_des, var_atcd, var_com, var_exam, var_ad), describe_all, d))
des_tot <- cbind(des_noSWAN[ , 1], des_SWAN[ , 1], des_all[ , 1:2])
des_tot <- des_tot[str_sub(rownames(des_tot), -1, -1)!=0, ] 
kable(des_tot)
```


# Exploratoire

```{r}
fpca(y="DTH30b", x= c(var_ad, var_atcd, var_exam, var_com, vardes), data=d, partial="No")

```


#Tests bivariés
```{r}
#TESTS BIVARIES : 

#Je retire ADLD3P et URIN1
var_exam <- c("DAS2D3PC", "DNR1", "SURV2MD1", "APS1", "SCOMA1", "WTKILO1", "TEMP1", "MEANBP1", "RESP1", "HRT1", "PAFI1", "PACO21", "PH1", "WBLC1", "HEMA1", "SOD1", "POT1", "CREA1", "BILI1", "ALB1")  
#var_exam <- var_exam [! var_exam %in% c("ADLD3P", "URIN1")]

#avec swanganz
list_swan <- lapply(c(var_ad, var_atcd, var_exam, var_com, vardes), function(x){
  print(x)
  d$var <- d[,x]
  if (all(levels(as.factor(d$var)) %in% c(0,1))) d$var <- as.factor(d$var) 
  mod <- glm(SWAN~var,d, family="binomial")
  test <- summary(mod)
  
  if (nrow(coef(test))>2){ #cas variable explicative qualitative
    test <- drop1(mod, .~., test="Chisq")
    ab <- test$`Pr(>Chi)`[2]
  } else {
    ab <- coef(test)[2, "Pr(>|z|)"]
  }
  ab <- round(ab, 3)
  ab <- data.frame(ab)
  ab$signif <- ifelse(ab$ab<0.05,"*","") 
  
  rownames(ab) <- x
  colnames(ab) <- c("coef pvalue SWAN","significatif SWAN")
  return(ab)
})
list_swan <- do.call(rbind, list_swan)

list_death <- lapply(c(var_ad, var_atcd, var_exam, var_com, vardes), function(x){
  print(x)
  d$var <- d[,x]
  if (all(levels(as.factor(d$var)) %in% c(0,1))) d$var <- as.factor(d$var) 
  #mod <- glm(DEATH~var,d, family="binomial")
  mod <- glm(DTH30b~var,d, family="binomial")
  test <- summary(mod)
  
  if (nrow(coef(test))>2){ #cas variable explicative qualitative
    test <- drop1(mod, .~., test="Chisq")
    ab <- test$`Pr(>Chi)`[2]
  } else {
    ab <- coef(test)[2, "Pr(>|z|)"]
  }
  ab <- round(ab, 3)
  ab <- data.frame(ab)
  ab$signif <- ifelse(ab$ab<0.05,"*","") 
  #ab$ab <- ifelse(ab$ab<0.001, "<0.001", ab$ab)
  rownames(ab) <- x  
  colnames(ab) <- c("coef pvalue DEATH","significatif DEATH")
  return(ab)
})
list_death <- do.call(rbind, list_death)

list_pval <- cbind(list_swan, list_death)

#prendre les valeurs : liées soit uniquement au décès, soit liées à la sonde et au décès (ce qui revient à prendre variable significative pour le décès ici) 
list_pval$select <- ifelse (list_pval$`coef pvalue DEATH`<0.05, 1, 0)
list_pval[list_pval$select==1, ]
nrow(list_pval[list_pval$select==1, ])
dput(rownames(list_pval[list_pval$select==1,]))
#c(rownames(list_pval[list_pval$select==1,])[c(1:8,12:36)],"CA","INCOME","NINSCLAS","CAT1")
#dput(rownames(list_pval[list_pval$select==1, ])) #pour éviter de tout taper à la main!ya plus qu'à copier coller

#var avec DEATH
# varps <- c("RESP", "GASTR", "RENAL", "HEMA", "SEPS", "TRAUMA", "ADLD3P", 
#            "DAS2D3PC", "DNR1", "CA", "SURV2MD1", "APS1", "SCOMA1", "WTKILO1", 
#            "TEMP1", "MEANBP1", "PACO21", "PH1", "HEMA1", "POT1", "CREA1", 
#            "BILI1", "ALB1", "URIN1", "CARDIOHX", "CHFHX", "DEMENTHX", "PSYCHHX", 
#            "CHRPULHX", "LIVERHX", "MALIGHX", "IMMUNHX", "TRANSHX", "AGE", 
#            "INCOME", "NINSCLAS", "CAT1", "CAT2")

#var avec DTH30b
varps <- rownames(list_pval[list_pval$select==1,])
print(varps)

#variables liées au décès et au traitement
rownames(list_pval[list_pval$`coef pvalue DEATH`<0.05 & list_pval$`coef pvalue SWAN`<0.05, ])
#variables liées uniquement au décès
rownames(list_pval[list_pval$`coef pvalue DEATH`<0.05 & list_pval$`coef pvalue SWAN`>=0.05, ])
#variables liées uniquement à la swan 
rownames(list_pval[list_pval$`coef pvalue DEATH`>=0.05 & list_pval$`coef pvalue SWAN`<0.05, ])
```
J'ai 9 classes au maximum (variable CAT1), donc la condition des 5 à 10 variables par variable est toujours respectée.
2 variables sont liées au décès uniquement : "TEMP1"   "LIVERHX"
34 variables sont liées au décès et au traitement par cathétérisme :
 "RESP"     "CARD"     "NEURO"    "GASTR"    "HEMA"     "SEPS"     "CAT1"     "CAT2"     "CA"      
 "DAS2D3PC" "DNR1"     "SURV2MD1" "APS1"     "SCOMA1"   "WTKILO1"  "MEANBP1"  "PAFI1"    "PACO21"  
 "PH1"      "WBLC1"    "HEMA1"    "CREA1"    "BILI1"    "ALB1"     "CARDIOHX" "CHFHX"    "DEMENTHX"
 "PSYCHHX"  "CHRPULHX" "GIBLEDHX" "MALIGHX"  "AGE"      "INCOME"   "NINSCLAS"
10 variables sontliées uniquement au cathétérisme : 
"RENAL"   "TRAUMA"  "RESP1"   "HRT1"    "SOD1"    "IMMUNHX" "TRANSHX" "AMIHX"   "SEX"     "EDU"

# Score de Propension

Afin d'équilibrer les groupes, je vais calculer un score de propension qui est la propabilité pour chaque patient d'être traité par la sonde de swan ganz. Pour cela je crée un modèle linéaire avec comme outcome le traitement par swan ganz et comme variables explicatives toutes les variables liées au décès à 30j uniquement(facteurs pronostiques) ou au décès et au traitement(facteurs de confusion). Je n'intègre pas les variables liées uniquement au traitement pour ne pas perdre de puissance à la fin.

Condition de validité :
C'est une régression logistique, je dois avoir 5 à 10 évènement par variable. J'ai 36 variables explicatives dans le score de propension dont 5 variables qualitatives : 9 classes pour CAT1, 7 classes pour CAT2, 3 classes pour CA, 4 classes pour INCOME, 6 classes pour NINSCLAS. Ces variables qualitatives seront donc transformées en 9+7+3+4+6-5= 24 variables binaires. Soit l'équivalent de 36-5+24 = 55 variables dans le modèle logistique pour 2184 évènements. J'ai donc plus de 10 évènements par variable explicative, les conditions de validité sont respectées.

```{r}
#score de propension
ps <- glm(formula(paste0("SWAN ~ ",paste(varps,collapse="+"))), data = d, family="binomial")

d2 <- d[apply(apply(d[ ,varps], 2, is.na),1,sum)==0, ] #J'elimine les lignes avec au moins 1 NA dans les variables slectionnes varps
d2$logitps <- as.vector(predict(ps, type = "response")) #response is the default for binomial model


#Histogramme du score de propension en fonction du groupe de traitement
prs_df <- data.frame(pr_score = predict(ps, type = "response"), 
                     SWAN = ps$model$SWAN)
labs <- paste("actual intervention:", c("no SWAN-GANZ", "SWAN-GANZ"))
prs_df %>%
  mutate(SWAN = ifelse(SWAN == 1, labs[2], labs[1])) %>%
  ggplot(aes(x = pr_score)) +
  geom_histogram(color = "white") +
  facet_wrap(~SWAN) +
  xlab("Probability of having a SWAN GANZ") +
  theme_bw()

```

Figure x. Distribution de la probablité d'être cathétérisé selon qu'ils ont effectivement été cathétérisé ou non.  

On voit que la distribution du score n'est pas la même parmi les patients ayant été cathétérisé et ceux n'ayant pas été cathétérisé : beaucoup de patient n'ayant pas été cathétérisé avait une faible probabilité d'être cathétérisé (distribution en L), alors que la distribution est plutôt en cloche centré autour de 0.5(distribution en cloche). On comprend donc que nécessairement l'appariemment va supprimer de nombreux patients.

## nombre de patients gardés

#Appariemment sur le score de propension

```{r}
#=============================
#Package Matching : 
#cours de David Hajage, MD PhD, département de biostatistiques de la Pitié Salpétriêre

#-----
#Le traitement (ici SWan Ganz) doit être en true false pour le package matching
d2$SWANT <- ifelse(d2$SWAN==1, T, F)

#-----
#appariement
tmp <- Match(Tr = d2$SWANT, X = d2$logitps, M = 1, replace = FALSE, caliper = 0.2, ties = FALSE)
#NB : ties=FALSE est l'équivalent de ratio=1 de MatchIt

#-----
#reconstitution du tableau avec les sujets appariés
d2.app <- d2[c(tmp$index.treated, tmp$index.control),]#index.treated et index.control donne le numero des lignes selectionnees par le matching. Le premier individu de index.treated est matchée avec le 1er de index.ctrl. 

#-----
#reconstitution du numéro de paire
d2.app$paire <- rep(1:length(tmp$index.treated), 2) #lignes de d2.app : d'abord les traités de chaque paire puis les control de chaque paire, donc on répète le numéro de paire
d2.app <- d2.app[order(d2.app$paire, d2.app$SWAN==1),] #on réordonne selon la paire SG(1)NSG(1) SG(2)NSG(2) etc
#=> donc ce tableau prend toutes les variables, uniquement les lignes correspondant aux individus matché et pour chaque individu on connait son numéro de paire


#=============================
#package MatchIt
#https://stanford.edu/~ejdemyr/r-tutorials-archive/tutorial8.html#exercise
#https://stanford.edu/~ejdemyr/r-tutorials-archive/matching.R

#-----
#appariement
mod_match <- matchit(formula(paste0("SWAN ~ ",paste(varps,collapse="+"))),
                     method = "nearest", replace = FALSE, ratio = 1, m.order = "smallest", caliper=0.2, data = d2[,c("SWAN",varps,"PTID")])
#MatchIt ne sait pas gérer les NA (même si les colonnes de la formule n'ont pas de NA) => Je dois préciser les colonnes qui m'interesse dans data (celles où je sais qu'il n'y a pas de NA)
#par exemple j'ai toujours des NA pour DTH30b

#-----
#reconstitution du numéro de paire
matches<-data.frame(mod_match$match.matrix)

# > dim(matches)
# [1] 2025    1
#2025 lignes, qui correspondent aux 2025 individus traités (avant matching)

# > head(matches)
#       X1
#   2  <NA>
#   5   927
#   10 2383
#le patient SWAN de la ligne nommée 2 du tableau d2  n'est matché avec aucun patient non SWAN : il faut eliminer la ligne
#le patient SWAN de la ligne nommée 5 du tableau d2 est matché avec le patient non SWAN de la ligne nommée 927

#J'élimine les les lignes avec NA (correspond aux traités qui n'ont pas été appariée)
matches <- na.omit(matches)
#position de chaque patient traité dans le tableau d2
groupSG1<-match(row.names(matches), row.names(d2)) 
#position de chaque patient non traité dans d2
groupSG0<-match(matches$X1, row.names(d2)) 

#-----
#reconstitution du tableau avec les sujets appariés et leur numéro de paire
d2.appbis <- d2[c(groupSG1, groupSG0),]
d2.appbis$paire <- rep(1:length(groupSG1), 2) 
d2.appbis <- d2.appbis[order(d2.appbis$paire, d2.appbis$SWAN==1), ]

#si jamais j'ai finalement besoin des distances :
dta_m <- match.data(mod_match) 
dtm <- merge(d2.appbis, dta_m[,c("PTID","distance","weights")], by="PTID", all=T)

#=============================
#J'ai donc deux tableaux : 
#dtm pour celui crée avec le package MatchIt 
#d2.app pour celui crée avec le package Matching
#la seule différence est que Matching garde plus d'individu et qu'il a l'air plus simple d'utilisation.

```

A partir du score de propension, je vais apparier un sujet cathétériser avec un sujet non cathétérisé ayant un score de propension proche c'est à dire une probabilité d'être cathétérisé proche. Le sujets non appariés sont écartés de l'analyse. Les sujets devrait donc se ressembler dans les 2 groupes. J'utilise un caliper de 0.2, c'est à dire un seuil d'appariemme,t de 0.2 x sd(logit(score de propension)). 


# Vérification de l'équilibre des variables entre les deux groupes après appariemment

Je transforme les qualitatives en binaires. 

```{r}
#jeu apparié (package matching)
dbis <- d2.app
for (j in varps_quali){
  num <- which(varps_quali==j)
  a <- model.matrix( ~ dbis[ ,j])
  #pour avoir un nom de variable reconnaissable dans les schéma (si on laisse tel quel ça donne dbis[ ,j] CHF par exemple)
  colnames(a) <- gsub("dbis",j,  colnames(a))
  colnames(a) <- gsub("\\[", "",  colnames(a))
  colnames(a) <- gsub("\\]", "",  colnames(a))
  colnames(a) <- gsub("\\,", "",  colnames(a))
  colnames(a) <- gsub("j", "",  colnames(a))
  colnames(a) <- gsub(" ", "_",  colnames(a))
  #créer les  variables binaires
  for (i in 1:(length(colnames(a))-1)){
    dbis[ ,colnames(a)[i+1]] <- a[ ,i+1]
  }
  #créer un vecteur avec les noms de variables bianires crées
  vec_tmp <- colnames(a)[-1]
  vec_var <- if(num==1) vec_tmp else c(vec_tmp, vec_var) 
}
#retirer les variables qualitatives non binarisees
dbis[ ,varps_quali] <- NULL
d2_app_b <- dbis

#jeu apparié (package matchit)
dbis <- dtm
for (j in varps_quali){
  num <- which(varps_quali==j)
  a <- model.matrix( ~ dbis[ ,j])
  #pour avoir un nom de variable reconnaissable dans les schéma (si on laisse tel quel ça donne dbis[ ,j] CHF par exemple)
  colnames(a) <- gsub("dbis",j,  colnames(a))
  colnames(a) <- gsub("\\[", "",  colnames(a))
  colnames(a) <- gsub("\\]", "",  colnames(a))
  colnames(a) <- gsub("\\,", "",  colnames(a))
  colnames(a) <- gsub("j", "",  colnames(a))
  colnames(a) <- gsub(" ", "_",  colnames(a))
  #créer les  variables binaires
  for (i in 1:(length(colnames(a))-1)){
    dbis[ ,colnames(a)[i+1]] <- a[ ,i+1]
  }
  #créer un vecteur avec les noms de variables bianires crées
  vec_tmp <- colnames(a)[-1]
  vec_var <- if(num==1) vec_tmp else c(vec_tmp, vec_var) 
}
#retirer les variables qualitatives non binarisees
dbis[ ,varps_quali] <- NULL
dtm_b <- dbis

#jeu total
dbis <- d2
for (j in varps_quali){
  num <- which(varps_quali==j)
  a <- model.matrix( ~ dbis[ ,j])
  #pour avoir un nom de variable reconnaissable dans les schéma (si on laisse tel quel ça donne dbis[ ,j] CHF par exemple)
  colnames(a) <- gsub("dbis",j,  colnames(a))
  colnames(a) <- gsub("\\[", "",  colnames(a))
  colnames(a) <- gsub("\\]", "",  colnames(a))
  colnames(a) <- gsub("\\,", "",  colnames(a))
  colnames(a) <- gsub("j", "",  colnames(a))
  colnames(a) <- gsub(" ", "_",  colnames(a))
  #créer les  variables binaires
  for (i in 1:(length(colnames(a))-1)){
    dbis[ ,colnames(a)[i+1]] <- a[ ,i+1]
  }
  #créer un vecteur avec les noms de variables bianires crées
  vec_tmp <- colnames(a)[-1]
  vec_var <- if(num==1) vec_tmp else c(vec_tmp, vec_var) 
}
#retirer les variables qualitatives non binarisees
dbis[ ,varps_quali] <- NULL
d2_b <- dbis

#nouvelles variables varps
varps_new <- names(dbis)[names(dbis) %in% varps]
new_bin <- names(dbis)[! names(dbis) %in% names(d2)]
varps_new <- c(varps_new, new_bin)

#je sépare les variables binaires des autres variables quantatives
varps_quanti2 <- varps_new[sapply(varps_new, function(variable) length(levels(as.factor(dbis[,variable]))) > 2)] #maintenant qu'il n'y a plus que des quanti binaire et non binaire, je peux transformer les quanti en facteur et dire que si plus de 2 levels, c'est une quanti non binaire.
varps_binaire <- varps_new[!varps_new%in% varps_quanti2]

```

```{r}
#-----------------
# Checking balance : 
#a faire uniquement sur les variables servant à construire le score de propension, car permet de voir
#si le score et le matching ont bien marché

#METHODE 0 : 
MatchBalance(formula(paste0("SWANT ~ ",paste(varps_new,collapse="+"))), data=d2_b, match.out=tmp) #package Matching

# #METHODE 1 : moyenne pour chaque variable à chaque point de score de ponpension
# #pb : ne marche qu'avec le package matchit car il faut la variable distance
# #Attention : variables quali : il faut les transformer en binaire
# varps_quanti <- varps[sapply(varps, function(variable) length(levels(dtm[,variable]))<=2)]#levels des variables quanti non bianire=NULL donc lenght=0
# varps_quali <- varps[!varps%in% varps_quanti]
# 
# 
# #fonction qui plot la distribution des variables en fonction du score de propension avant et après matching
# fn_bal <- function(dta, variable) {
#   #browser()
#   dta$variable <- dta[, variable]
#   dta$SWAN <- as.factor(dta$SWAN)
#   ggplot(dta, aes(x = distance, y = variable, color = SWAN)) +
#     geom_point(alpha = 0.2, size = 1.5) +
#     geom_smooth(method = "loess", se = F) +
#     xlab("Propensity score") +
#     ylab(variable) +
#     theme_bw()
# }
# 
# .l <- lapply(c(varps_quanti2, varps_binaire), function(variable){
#   print(variable)
#   num <- which(c(varps_quanti2, varps_binaire)==variable)
#   if (num %% 2 != 0) fn_bal(dtm_b, variable)
#   else fn_bal(dtm_b, variable) + theme(legend.position = "none")
# })
# 
# ml <- marrangeGrob(.l, nrow=2, ncol=2, top = NULL)
# ggsave(file="distrib mean variables after matching 20170320.pdf", ml)

#============================
#METHODE 2 : standardized mean difference avec matchit (variance du groupe traitement)

#https://cran.r-project.org/web/packages/tableone/vignettes/smd.html
#https://github.com/kaz-yos/tableone/blob/1d47ec186b2e351937e5f9712dad3881380ab12e/vignettes/smd.Rmd

#Le package matchit fournit une différence standardisée
smd1 <- summary(mod_match, standardize = TRUE) #fait la balance pour chaque binaire tirée de la variable quali
dataplot <- data.frame(variable = rownames(smd1$sum.all), 
                       unmatched = abs(smd1$sum.all[,"Std. Mean Diff."]), 
                       matched = abs(smd1$sum.matched[,"Std. Mean Diff."]))
dataplotmelt <- melt(data          = dataplot,
                     id.vars       = c("variable"),
                     variable.name = "Method",
                     value.name    = "SMD")
colnames(dataplotmelt) <- c("variable","Method","SMD")
varNames <- as.character(dataplot$variable)[order(dataplot$unmatched)]
#organise les variables dans le plot en fonction de la valeur de smd unmatched
dataplotmelt$variable <- factor(dataplotmelt$variable,
                                levels = varNames)
ggplot(data = dataplotmelt[!dataplotmelt$variable %in% c("distance","SWAN"), ], mapping = aes(x = variable, y = SMD,
                                          group = Method, color = Method)) +
  geom_point() +
  geom_hline(yintercept = 0.1, color = "red", size = 0.1) +
  coord_flip() +
  theme_bw() + theme(legend.key = element_blank())


#mais en vérifiant avec la variable AGE je vois qu'ils utilisent la formule avec la variance du groupe traitement et non pas la variance commune (Austin et al 2011).
mymean <- as.numeric(by(d2[,"AGE"], d2$SWAN, mean))
mysd <- as.numeric(by(d2[,"AGE"], d2$SWAN, sd))
(mymean[2]- mymean[1])/sqrt((mysd[2]^2+mysd[1]^2)/2) #smd avec la variance commune
(mymean[2]- mymean[1])/mysd[2] #smd avec l'écart-type du groupe traitement : correspond au smd donné par matchit

#et les variables quali sont transformées en k variables binaire et non k-1, avec k le nombre de classes.

#============================
#METHODE 2 BIS standardized mean difference avec variance commune

#-----
#unmatched
dbis <- d2_b
#calcul de smd pour les variables quantitatives non binaires
smd_quanti_um <- data.frame(smd = sapply(varps_quanti2, function(x){
  mymean <- as.numeric(by(dbis[,x], dbis$SWAN, mean))
  mysd <- as.numeric(by(dbis[,x], dbis$SWAN, sd))
  mysmd <- abs((mymean[2]- mymean[1])/sqrt((mysd[2]^2+mysd[1]^2)/2))
  #mysmd <- (mymean[2]- mymean[1])/mysd[2]
  return(mysmd)
}), variable = varps_quanti2)

smd_bin_um <- data.frame(smd = sapply(varps_binaire, function(x){
  mymean <- as.numeric(by(dbis[,x], dbis$SWAN, mean))
  mysmd <- abs((mymean[2]- mymean[1])/sqrt((mymean[2]*(1 - mymean[2]) + mymean[1]*(1 - mymean[1]))/2))
  #mysmd <- (mymean[2]- mymean[1])/mysd[2]
  return(mysmd)
}), variable = varps_binaire)
smdum <- rbind(smd_quanti, smd_bin)

#-----
#matched
dbis <- d2_app_b

#calcul de smd pour les variables quantitatives non binaires
smd_quanti_m <- data.frame(smd = sapply(varps_quanti2, function(x){
  mymean <- as.numeric(by(dbis[,x], dbis$SWAN, mean))
  mysd <- as.numeric(by(dbis[,x], dbis$SWAN, sd))
  mysmd <- abs((mymean[2]- mymean[1])/sqrt((mysd[2]^2+mysd[1]^2)/2))
  #mysmd <- (mymean[2]- mymean[1])/mysd[2]
  return(mysmd)
}), variable = varps_quanti2)

smd_bin_m <- data.frame(smd = sapply(varps_binaire, function(x){
  mymean <- as.numeric(by(dbis[,x], dbis$SWAN, mean))
  mysmd <- abs((mymean[2]- mymean[1])/sqrt((mymean[2]*(1 - mymean[2]) + mymean[1]*(1 - mymean[1]))/2))
  #mysmd <- (mymean[2]- mymean[1])/mysd[2]
  return(mysmd)
}), variable = varps_binaire)
smdm <- rbind(smd_quanti_m, smd_bin_um)

#construction du plot
#quanti
dataplot <- data.frame(variable = smd_quanti_m$variable, unmatched = smd_quanti_um$smd, matched = smd_quanti_m$smd)
dataplotmelt <- melt(data = dataplot, id.vars = "variable", variable.name = "Method", value.name = "SMD")
colnames(dataplotmelt) <- c("variable","Method","SMD")
varNames <- as.character(dataplot$variable)[order(dataplot$unmatched)]
#organise les variables dans le plot en fonction de la valeur de smd unmatched
dataplotmelt$variable <- factor(dataplotmelt$variable,
                                levels = varNames)
ggplot(data = dataplotmelt[!dataplotmelt$variable %in% c("distance","SWAN"), ], 
       mapping = aes(x = variable, y = SMD, group = Method, color = Method)) +
  geom_point() +  geom_hline(yintercept = 0.1, color = "red", size = 0.1) +
  coord_flip() +  theme_bw() + theme(legend.key = element_blank(), legend.title = element_blank())
#binaire
dataplot <- data.frame(variable = smd_bin_m$variable, unmatched = smd_bin_um$smd, matched = smd_bin_m$smd)
dataplotmelt <- melt(data = dataplot, id.vars = "variable", variable.name = "Method", value.name = "SMD")
colnames(dataplotmelt) <- c("variable","Method","SMD")
varNames <- as.character(dataplot$variable)[order(dataplot$unmatched)]
#organise les variables dans le plot en fonction de la valeur de smd unmatched
dataplotmelt$variable <- factor(dataplotmelt$variable,
                                levels = varNames)
ggplot(data = dataplotmelt[!dataplotmelt$variable %in% c("distance","SWAN"), ], 
       mapping = aes(x = variable, y = SMD, group = Method, color = Method)) +
  geom_point() +  geom_hline(yintercept = 0.1, color = "red", size = 0.1) +
  coord_flip() +  theme_bw() + theme(legend.key = element_blank(), legend.title = element_blank())

#=============================

#METHODE 3 IC à la main
#voir comment calculer IC pou var quali binarisés
getMIC <- function(.data){
  dt <- lapply(names(.data)[names(.data) %in% varps_new], function(var){
    num <- which(var==names(.data)[names(.data) %in% varps_new])
    #standardisation
    .data[,var] <- (.data[,var] - mean(.data[,var]))/sd(.data[,var])  
    
    x <- .data[.data$SWAN == 1, var]
    df1 <- data.frame(mymean = mean(x),
                      ICminSG = mean(x) - 1.96*sqrt(var(x)/nrow(.data)),
                      ICmaxSG = mean(x) + 1.96*sqrt(var(x)/nrow(.data)),
                      myy = num*2-0.5,
                      groupe = "SWAN",
                      colour = 1)
    
    x <- .data[.data$SWAN == 0, var]
    df0 <- data.frame(mymean = mean(x),
                      ICminSG = mean(x) - 1.96*sqrt(var(x)/nrow(.data)),
                      ICmaxSG = mean(x) + 1.96*sqrt(var(x)/nrow(.data)),
                      myy = num*2+0.5,
                      groupe = "NO SWAN",
                      colour = 2)
    
    df <- rbind(df1,df0)
  })
  dt <- do.call(rbind, dt)
  dt$var <- rep(names(.data)[names(.data) %in% varps_new],each=2)
  return(dt)
}

#plot des var quanti
df <- getMIC(d2_app_b[ ,c("SWAN", varps_quanti2)])
df <- na.omit(df) #retire les var quali dont les IC n'ont pas été calculés

m<-tapply(df$myy, df$var, mean)
m<-data.frame(var=names(m), y=m)

df2<-merge(df, m, by="var", all=T)
df2<-df2[order(df2$var, df2$group),]
df2$y<-ifelse(df2$groupe=="SWAN", 0.25, -0.25)+df2$y

laby<-unique(df2$var)

col <- hue_pal()(length(1:2))

g <- ggplot(data=df2, aes(x=mymean, xmin = ICminSG, y = y, xend = ICmaxSG, colour=groupe)) + geom_point() 
g <- g + labs(y = "variable")
g<-g+scale_y_continuous(name="Variables", breaks=m$y, labels=m$var)
g

for (i in 1:nrow(df)){
  g <- g + geom_segment(x = df2$ICminSG[i], y = df2$y[i], xend = df2$ICmaxSG[i], yend = df2$y[i], colour = col[df2$colour[i]])
  g <- g + geom_segment(x = df2$ICminSG[i], y = df2$y[i]-0.5, xend = df2$ICminSG[i], yend = df2$y[i]+0.5, colour = col[df2$colour[i]])
  g <- g + geom_segment(x = df2$ICmaxSG[i], y = df2$y[i]-0.5, xend = df2$ICmaxSG[i], yend = df2$y[i]+0.5, colour = col[df2$colour[i]])
}
g

#plot des var binaire
df <- getMIC(d2_app_b[ ,c("SWAN", varps_binaire)])
df <- na.omit(df) #retire les var quali dont les IC n'ont pas été calculés

m<-tapply(df$myy, df$var, mean)
m<-data.frame(var=names(m), y=m)

df2<-merge(df, m, by="var", all=T)
df2<-df2[order(df2$var, df2$group),]
df2$y<-ifelse(df2$groupe=="SWAN", 0.25, -0.25)+df2$y

laby<-unique(df2$var)

col <- hue_pal()(length(1:2))

g <- ggplot(data=df2, aes(x=mymean, xmin = ICminSG, y = y, xend = ICmaxSG, colour=groupe)) + geom_point() 
g <- g + labs(y = "variable")
g<-g+scale_y_continuous(name="Variables", breaks=m$y, labels=m$var)
g

for (i in 1:nrow(df)){
  g <- g + geom_segment(x = df2$ICminSG[i], y = df2$y[i], xend = df2$ICmaxSG[i], yend = df2$y[i], colour = col[df2$colour[i]])
  g <- g + geom_segment(x = df2$ICminSG[i], y = df2$y[i]-0.5, xend = df2$ICminSG[i], yend = df2$y[i]+0.5, colour = col[df2$colour[i]])
  g <- g + geom_segment(x = df2$ICmaxSG[i], y = df2$y[i]-0.5, xend = df2$ICmaxSG[i], yend = df2$y[i]+0.5, colour = col[df2$colour[i]])
}
g

```

Tout d'abord, je transforme mes variables qualitatives en n-k variables binaires, k étant le nombre de classe de la variable qualitative.  
J'ai ensuite plusieurs méthodes possibles pour regarder si l'appariemment a équilibré la distribution des variables dans le groupe traité et non traité : 
-  je peux regarder la moyenne de chaque variable en fonction du score de popension. Je vois donc pour des patients de ces 2 groupes ayant la même probabilité d'être traité, si la moyenne de la variable est semblable. Bien sûr si les courbes se superposent parfaitement, on peut dire que la distribution est semblable dans les deux groupes.Si elles sont disjointes à certaines valeures d'abscisse, nous pouvont dire que pour les individus ayant tel probabilité d'être traité, la moyenne des variables diffèrent. Ainsi dans les courbes présentées en annexe, on voit ainsi que les individus avec une forte probabilité d'être traité ont une moyenne qui semble différer entre les deux groupes pour INCOME, NINCLAS, RESP et SEPS, et que les individus avec une faible probabilité d'être traité ont une moyenne qui semble différer poyr les variables RESP, HEMA et DNR1.  Or il me semble qu'on ne cherche pas à ce que les individus ayant la même probabilité d'être traité soit exactement semblable 2 à 2 (même si bien sûr c'est idéal) mais plutôt que les populations des groupes traités et non traités soit homogène, comme c'est le cas lorsque l'on randomise. Il me semble donc plus pertinent de voir si globablement les distribution sont les mêmes dans les deux groupes, et les deux méthodes présentées ci dessous répondent à cette question.  
-  je regarde la différence standardisée des moyennes(smd), c'est à dire la différence entre la moyenne dans le groupe cathétérisé et la moyenne dans le groupe non cathétérisé divisé par la variance commune. J'ai séparé les schémas en variable binaire et variable quantitative non binaire pour plus de visibilité. En instaurant un seuil de smd à 0.1 comme conseillé dans la littérature, je vois que l'appariemment établi un équilibre entre les deux groupes pour toutes les variables. 



